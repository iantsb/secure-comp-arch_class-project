%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is the template for submission to MICRO 2019
% The cls file is modified from 'sig-alternate.cls'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[conference]{IEEEtran}
\usepackage{mathptmx} % This is Times font
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage[normalem]{ulem}
\usepackage[hyphens]{url}
\usepackage[sort,nocompress]{cite}
\usepackage[final]{microtype}
\usepackage{flushend}
% Always include hyperref last
\usepackage[bookmarks=true,breaklinks=true,letterpaper=true,colorlinks,linkcolor=black,citecolor=blue,urlcolor=black]{hyperref}

% Ensure letter paper
\pdfpagewidth=8.5in
\pdfpageheight=11in

\pagenumbering{arabic}


%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\title{Final Report\protect\\ \large December 2025}
\author{\IEEEauthorblockN{Ian Barnaby}
        \IEEEauthorblockN{Ryn Stewart}
        \IEEEauthorblockN{Tome Dudanov}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle
\pagestyle{plain}



%%%%%% -- PAPER CONTENT STARTS-- %%%%%%%%

\section{Problem Statement}
In-memory computing to accelerate AI requires neural networks weights to be encoded in non-volatile memory (NVM). Current heterogeneous systems require weights to be communicated from CPU to accelerator, potentially in an untrusted environment. At present, there is no way to encrypt these weights in NVM to allow for correct neural network function. Securing this operation therefore (currently) requires encrypting/decrypting weights as communicated from CPU to accelerator to prevent snooping/monitoring attacks; however, as many of these applications are low-power, this proves difficult with a constrained area/power budget. This project seeks to describe a method of weight encryption in these systems leveraging existing device properties to reduce security overhead. 

\section{Motivation}
Non-volatile memory (NVM) has emerged as a new memory paradigm in recent years, offering non-dynamic system memory that does not require refreshing. This type of memory has also been used for in-memory computing (IMC), as the two-terminal nature of certain NVM implementations (such as ReRAM \cite{reram_imc}) allow for direct operation within the memory cells. This has become especially relevant for ML applications, in which neural networks may be directly mapped to a crossbar array of NVM cells \cite{array}. Security in NVM cells is already a challenge due to data longevity, but has been researched using Bonsai-Merkle Trees (BMT) to secure the memory \cite{bmt_nvm}. While effective in NVM for system memory, this is not an option for IMC, as the crossbar array must hold unencrypted values for correct neural network operation. 

In the SLEAC project \cite{sleac}, the CPU/accelerator system consists of a CPU, IMC accelerator, and a data bus connecting the two. This system is prone to snooping attacks on the bus as weight values, along with their location within the array and instruction, are communicated from CPU to accelerator. Therefore, it is desired to determine a suitable encryption/decryption method for this unique low-power application such that instructions/data may be sent securely across the bus. 

\subsection{Threat Model}

\section{Experiment}
\subsection{Bus Encryption}
\label{subsec:bus_encryption}
We implemented three cryptographic approaches directly into the CPU-accelerator bus layer to secure any transfers such as MNIST weights. Each scheme has advantages and disadvantages, with clear differences in hardware.

The first encryption approach that we took was the 128-bit AES-GCM authenticated encryption mode with a PUF-derived secret key. We encrypt each chunk of the message sent, producing ciphertext and an authentication tag. The bus carries this encrypted message, including the GCM tag and nonce, while during decryption, each message is verified for integrity before it is loaded. This path assumes a safely pre-established symmetric key, derived from the PUF. However, AES alone cannot establish a shared key - it has to assume that the PUF key is already synchronized between the CPU and the accelerator, even though a PUF can only reside on one device, meaning the CPU and the accelerator cannot both derive the same secret without additional bus exchange. This highlights the need for additional work to ensure secrecy, as delivering plaintext shared keys on the bus exposes them to snooping.

One way to address this issue is to use the RSA cryptosystem directly for bus encryption, eliminating the need for sharing secrets over the bus. In our implementation, we split the plaintext into OAEP-sized (214-byte) blocks, and encrypt each block with RSA-2048. Additionally, we encrypt a SHA256 digest of the plaintext and append it to the message for integrity checking. The bus, hence, carries only RSA ciphertext blocks and metadata, which upon decryption is recovered and reassembled. Then, the appended hash is compared to a recomputed digest to reveal any tampering en route. Unlike AES, this approach does not require any pre-shared secrets, since RSA enables the CPU and accelerator to encrypt and decrypt directly with their respective private and public keys. However, the reliance on repeated expensive exponentiation adds significant computational overhead, only acceptable with sparse bus traffic.

To relieve the tension between secrecy and efficiency, our third and final cryptographic approach combines the best of both worlds: using a computationally expensive operation to establish a shared key between the parties securely, followed by fast encryption with a safely pre-established symmetric key. Specifically, we use elliptic-curve Diffie-Helman (ECDH) on the P-256 curve to derive a shared secret across the bus without the risks of snooping. Encryption and decryption afterwards happen symmetrically using AES-GCM, as discussed earlier in this section. This hybrid scheme therefore achieves a practical balance: secrecy is kept during key establishment, and efficiency is maintained during more frequent bus traffic.

These cryptographic schemes differ in hardware complexity as well as security implications. The hybrid ECDH + AES approach adds elliptic curve logic on top of the AES-GCM component, so the tradeoff is more hardware complexity than the other two schemes. Yet, no scheme is perfect. Symmetric encryption alone struggles with key exchange, pure asymmetric lacks in performance, and hybrid has additional implementation costs. Each of these designs has its trade-off, balancing secrecy, speed and hardware complexity differently.

\subsection{Weight Integrity}
In the case where pure RSA encryption is used, data integrity check for weights is added by appending a SHA256 hash (computed over the plaintext weights) ciphertext in its encrypted form, extending the encrypted block size by one. On the receiving side, the ciphertext is decrypted and the hash is stripped from the message. The SHA256 hash is then recomputed over the decrypted weights and compared with the received hash value. If the values are equal the weight update is successful, otherwise the update is ignored. This process design is shown in Figure \ref{flow diagram}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.75\linewidth]{encrypt_hash_flow_diagram.png}
    \caption{Overview of decryption and integrity checking upon a weight update.}
    \label{flow diagram}
\end{figure}

\subsection{PUF Design}
ReRAM cells have been examined by several works as a PUF source. These works are further examined in [] but show that ReRAM can be used as reliable and secure PUFs in a variety of manners. Common across these works, however, is the use of ReRAM PUFs without utilizing the ReRAM for memory. As the PUF designs are based on physical properties of the cell, the wear placed on the cells due to read/write operations change these properties and alters PUF behavior. As examined in [], this wear on the read/write times of the cells happens in a predictable manner and has reliable effects on the read/write time. 
Our approach aims to use ReRAM cells for both memory and key generation by accounting for the drift in read/write time and using it as a source of continued entropy. This allows for a design in which no extra ReRAM cells are used to generate cryptographic keys, conserving physical space and reusing existing devices. This also may allow for cryptographic generation in existing ReRAM implementations without extensive hardware changes. This would be an efficient way to improve security in ReRAM technologies and a novel way to use memory for dual purposes. 
A PUF bit is generated by race condition between two adjacent ReRAM cells in the SET times. This could either be done in the analog domain with a comparator between the bitlines, or in the digital domain based on the timing of the output bits. The actual implementation would come down to reliability and area overhead. To provide the challenge bits, several rows of ReRAM would be utilized, where the challenge bit selects which row is used for the comparison. The ReRAM would then be organized into “banks” (note, this is a purely organizational term and does not require any physical change) where each bank accesses a row determined by the challenge bits. For example, with 4 rows and 16 banks, each bank uses 2 challenge bits (2 bits to access 4 rows) to create a 32-bit challenge. This is shown in Figures [] through []. This method is made efficient by using the same wordline access per bank, allowing PUF generation to be parallelized. The challenge can also be made more robust by using challenge “rounds”, where this process is repeated several times. 
In an idealized approach, a 256 by 256 ReRAM array performs in-memory computation via matrix vector multiplication (MVM). When a cryptographic key is required, the challenge is provided, and specific ReRAM cells (likely the cells located closest to the readout) are used in a SET race to generate PUF bits. Once the key has been obtained, the ReRAM cells are re-programmed to their original state and resume MVM operation. If a digital readout is used to generate the PUF bits, it may be possible to do without any additional hardware and drive the computation purely by the ReRAM accesses. While not usable for fingerprinting (as the key changes over time) it would be a reliable random key generator.
The evaluation of this approach in this report will focus on two properties that may eventually be examined by experiment. First, the drift of the generated key over time as wear is placed on the ReRAM cells. It is important to understand how the key drifts over time to understand if it happens predictably or unpredictably. Second, the strength of the PUF generated by different configurations of the array. For example, PUF generation could be done with 4 rows of 256 columns organized into 16 banks, or 4 rows of 256 columns organized into a single bank with a round-based generation. The strength of the generated PUF will be evaluated based on the average bit mean (ideally 0.5) and average inter-Hamming distance (ideally 64 for a 128-bit key). This average will be taken over many initial seedings for the SET times of the ReRAM cells. This will allow us to determine the ideal configuration for bit generation when combined with a timing estimate that can generate a cryptographically secure key in the shortest possible time. 


\section{Evaluation}
\subsection{Encryption Performance Comparison}
To evaluate the practicality of each scheme described in Subsection~\ref{subsec:bus_encryption}, we measured encryption and decryption timing under identical bus traffic conditions. The results highlight clear distinctions: AES-GCM has the lowest latency, RSA-2048 suffers due to expensive operations, and the hybrid ECDH+AES-GCM approach occupies the middle ground - essentially incurring an initial cost for key establishment, then evening out close to AES with further transmissions. Figure 1 illustrates the measured latencies for all three schemes under identical bus traffic.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{secure_bus_comparison.png}
  \caption{Encryption method time comparison of the insecure bus, hashing only for integrity but no bus encryption, 128-bit AES-GCM encryption, ECDH key exchange with 128-bit AES-GCM encryption, and RSA-2048 encryption.}
  \label{encryption time chart}
\end{figure}

As shown in Figure \ref{encryption time chart}, the insecure bus baseline transmits the message in 0.130s, while hashing only for integrity without any encryption increases the time to 0.457s. AES-GCM gives us efficient protection, finishing in 0.802s, the hybrid ECDH+AES-GCM scheme incurs a higher cost of 1.510s, and RSA is by far the slowest with 5.819 seconds to fully encrypt, send the message over the bus, and decrypt it on the other side.

\subsection{Weight Integrity}
For an integrated functional simulation in python, the SHA256 class is used from the pycryptodome library. The integrity check was verified with a simple bit flipping function that XORs the ciphertext with a 64-bit mask where 1 bit is randomly set using the numpy random module. 

To obtain a power analysis of the SHA256 module, RTL from an open source github project\cite{SHA256} was synthesized with Vivado for an Artix 7 FPGA development board. This Verilog implementation of SHA256 has a 512-bit block input with a 256-bit disgest and executes 64 rounds of hashing, one round per cycle. Clockspeed was set to 50MHz. Using this test setup, the reported power of the RTL is detailed in Table \ref{power report}, notably the total is only 0.557W. 

\begin{table}[]
    \centering
    \begin{tabular}{ll}
    \hline
         Dynamic Power & 0.472W\\ \hline
         Static Power  & 0.085W \\ \hline
         Total Power   & 0.557W
    \end{tabular}
    \caption{SHA256 Power with 50MHz clock for FPGA dev board}
    \label{power report}
\end{table}

Based on this RTL project, the throughput can also be calculated by taking the number of cycles needed to complete hashing on a 512-bit block. Each block goes through 64 rounds of SHA256, and one round is executed per cycle, so the total time to execute is found by the following (assuming 50MHz for clockspeed): $64 cycles \times 20ns = 1.28\mu s$. Finally, one block contains 448 bits of data (512 - 64 bits for padding) leading to a throughput of 350Mbps. 

Although these metrics will be highly dependent on the specific technology the accelerator is implemented on, they demonstrate the feasibility of adding specialized hardware to implement secure hashing in terms of power requirements and throughput. Given the need for decryption in the threat model of this system, especially using an asymmetric algorithm, SHA256 is not a bottleneck and the power is reasonable given the overall application. However, future work could further explore lower overhead data integrity checks, such as cyclic redundancy check or parity bits, using encryption to keep the verification data secret to an attacker. 

\section{Related Works}
\subsection{Cycle Count Studies}
% \cite{Oder2014}
% \cite {Schwabe2016}
Cycle counts for encryption vary not only depending on the encryption algorithm itself, but also on the machine itself, primarily on the CPU. A cycle count, therefore, is not measured by the algorithm itself, but benchmarked on different hardware to capture performance for that specific hardware. Prior work has shown that AES can be implemented with low cycle counts on Cortex M3 and M4 microcontrollers \cite{Schwabe2016}, while ECC and RSA are more computationally heavy \cite{Oder2014}. In our bus setup of 256-bytes at a time, AES-128 requires a one-time key expansion encryption and decryption, as well as 16 16-byte blocks encrypted and sent. This would take a total of 1469.4 cycles for key expansion, and 20960 cycles for encryption and decryption \cite{Schwabe2016}, a total of 22429.4 for a single encryption and decryption operation on the ARM Cortex M4. This figure excludes the additional cost of hashing verification. On the other hand, for RSA-2048 to encrypt and decrypt a message, on the same microcontroller, it would take 228068226 cycles to sign, and 6195481 cycles to verify \cite{Oder2014}, a total of 234263707 cycles excluding a one-time keygen cost and hashing verification. ECC-256 balances both schemes out, incurring a one-time cost of 12713277 cycles for key gen, 13102239 cycles to sign, and 24702099 cycles to verify - a total of 50517615 \cite{Oder2014}, then every message from then on will be encrypted/decrypted using AES, and therefore has its cost. Note that the ECC-256 asymmetric key exchange portion is still costly, but much less costly than RSA's operation.

\subsection{Integrity checking for Model Weights}
Data integrity for DNN weights has become an increasingly relevant topic as the adoption of models has moved to edge compute, requiring quantization of weights. Previous works \cite{deephammer}, \cite{TBFA} have shown the effectiveness of bit-flip attacks (BFAs) on model inference, either to subtly change predictions or to completely destroy accuracy to the level of a random guess. In response to this, there have been several proposed mitigations that add data integrity checks to weights during the online operation of a model.

For example, HashTAG \cite{HASHTAG} attempts to resolve the issue by generated Pearson hashes prior to model deployment and storing them as "ground-truth signatures" per DNN layer. The hashes are stored in secure SRAM and compared against hashes recomputed during operation. This work's use of Pearson hashing allows for a low overhead (8-bit hash computed with a 256 value look-up table) data integrity check, but still leaves the model susceptible to a BFA due to collisions. Additionally, this method would not work for the system described in this paper as the expected hashes have to be precomputed and stored in secure memory. 

Another low overhead mitigation is LIMA \cite{LIMA}. Here, the authors propose encoding the data integrity check into the weights themselves by modifying a K (defined per system) number of LSBs such that the sum of K MSBs and LSBs equals 0 per DNN layer. The key insight from this work is that the LSBs of the quantized weights minimally impact the accuracy of the model. LIMA does not increase memory overhead and only requires multiply and accumulate operations to verify integrity. However, the mitigation is still leaves a model vulnerable as an attacker could flip bits in the weights such that the LSBs and MSBs still sum to 0. Another note is that LIMA caught single bit-flips only 70.5\% of the time in the worst case.   

\subsection{Neurohammer}
Neurohammer presents an attack on ReRAM non-volatile memory similar to the row hammer attack in DRAM. This paper has little relevance to the work presented in this project but presents a possible security concern for ReRAM designs. The attack utilizes thermal crosstalk between adjacent ReRAM cells to cause intentional bit flips. In this scheme, the attacker cell is repeatedly pulsed with a high voltage, causing the cell’s temperature to rapidly increase. Thermal coupling between the attacker and victim cell causes the victim cell to also increase in temperature. Once heated, lower voltage pulses (at the level of read voltage of ReRAM cells) will be sufficient to cause bit flips. Essentially, this means that repeated attacker accesses will cause future reads on victim cells to alter the victim state and cause a bit flip. The authors then simulate a Neurohammer attack and demonstrate that it can effectively cause bit flips. Since row hammer represents both a security and reliability concern, Neurohammer defenses may be required for secure ReRAM implementations.

\subsection{ReRAM PUFs}
ReRAM PUF methods have been studied extensively. The key issue with ReRAM PUFs is the variability due to read voltage and temperature, reducing repeatability. Our approach relies on ReRAM for random key generation on device startup and does not need to be repeatable, but it still important to consider how the devices made be made more reliable for the purpose of read out. One approach solves the issue of read disturbance by operating at very low read voltages. In the paper Design and Analysis of Pre-formed
ReRAM-Based PUF [], unformed ReRAM cells are read out using very low read currents (110 nA) to reliably generate entropy based on observed conductance. While this method does display temperature variance, they demonstrate it to be reliable across separate reads with an average of 0.30\% intra-cell variation. Of course, this method relies on unformed PUFs and prevents the ReRAM device from being used for any other purpose. Additionally, if current increases and the ReRAM becomes programmed, the PUF is permanently lost. It may be that this method would not even be suitable as a entropy source after programming, as it will simply read out current state. 
Another paper, Re4PUF [], proposes to increase reliability by substantially increasing the footprint of the PUF. In this configuration, they use a 3T2R cell per PUF: two ReRAM cells, one select transistor, and one inverter. Their topology creates a voltage divider across the ReRAM cells, taking the output voltage and binarizing it with an inverter to reduce fluctuations. They prove their design to be robust and secure, forming a strong PUF with very low bit error rate. Unfortunately, they have not performed any temperature analysis and results cannot be assumed to be positive. This is still likely a strong method for PUF generation in ReRAM, but requires entirely separate structures independent of any ReRAM crossbar array.



\subsection{Hiding Information in ReRAM Cells}
This paper demonstrates a technique for covert data storage in ReRAM devices []. The researchers state that the set/reset time of
a ReRAM cell changes with each write cycle. This occurs due to oxygen vacancies in the oxide layer used to construct the conductive
filament and limits the total number of write cycles the cell can handle before it no longer functions. The researchers have observed
that, once the set/reset characteristics of a cell have been altered, they can reliable determine cells with more or less "wear". By
setting a point at which set/reset times can be read as binary "1" or "0", cells can intentially be worn down to encode values in the
set/reset time. The researchers demonstrate that fresh cells can be worn down in desired bit patterns, and the data can be be reliably
recovered until a threshold is reached. After a certain number of write cycles, the data encoded in the set/reset time becomes too 
noisy. As such, this paper provides the basis for this work of establishing a method of encoding data within ReRAM cells separate from 
the memory values, that changes based on how many writes have been issued to the device.

%%%%%%% -- PAPER CONTENT ENDS -- %%%%%%%%


%%%%%%%%% -- BIB STYLE AND FILE -- %%%%%%%%
\bibliographystyle{IEEEtranS}
\bibliography{refs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
